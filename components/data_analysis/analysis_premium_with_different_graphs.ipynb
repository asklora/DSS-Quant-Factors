{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import glob\n",
    "import os \n",
    "from typing import List\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import Engine\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sqlalchemy engine\n"
     ]
    }
   ],
   "source": [
    "# Utility functions\n",
    "url = f\"postgresql://quant_factor:quant_factor@192.168.1.156:5432/quant_dev\"\n",
    "kwargs = dict(pool_size=1, max_overflow=-1, isolation_level=\"AUTOCOMMIT\", pool_pre_ping=True, pool_recycle=600,\n",
    "                      echo=False)\n",
    "\n",
    "def creating_engine():\n",
    "    print(f\"Creating sqlalchemy engine\")\n",
    "    engine = create_engine(url,**kwargs)\n",
    "    return engine\n",
    "\n",
    "engine = creating_engine()\n",
    "\n",
    "def read_factor_formula_ratios():\n",
    "    query = f\"\"\"SELECT name, is_active, smb_positive , pillar FROM factor.factor_formula_ratios;\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        print(f\"Reading table\")\n",
    "        df = pd.read_sql(query,connection, index_col = ['name'])\n",
    "    return df\n",
    "\n",
    "def read_table_all_from_factor_processed_ratio_20_pct():\n",
    "    query = 'SELECT * FROM factor.factor_processed_premium_20_pct;'\n",
    "    with engine.connect() as connection:\n",
    "        print(f\"Reading table all\")\n",
    "        df_20_pct = pd.read_sql(query,connection, index_col = ['testing_period','field','group','weeks_to_expire','average_days'])\n",
    "    return df_20_pct\n",
    "    \n",
    "def read_table_all_from_factor_processed_ratio_20_pct_with_specified_market(market: str = 'USD'):\n",
    "    query = f\"\"\"SELECT * FROM factor.factor_processed_premium_20_pct WHERE \"group\"='{market.upper()}';\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        print(f\"Reading table all with market = {market.upper()}\")\n",
    "        df_20_pct_specified_mkt = pd.read_sql(query,connection, index_col = ['testing_period','field','group'])\n",
    "        df_20_pct_specified_mkt = df_20_pct_specified_mkt.drop(columns=['weeks_to_expire','average_days', 'updated'])\n",
    "    return df_20_pct_specified_mkt\n",
    "\n",
    "def merge_factor_ratio_with_smb_and_retain_active_factor(df_unprocessed: pd.DataFrame = None):\n",
    "    formula = read_factor_formula_ratios()\n",
    "    formula = formula.reset_index()\n",
    "\n",
    "\n",
    "    active_factor = formula.loc[(formula['is_active']==True) & ~(formula['smb_positive'].isnull())]['name'].tolist()\n",
    "    formula_merge = formula.loc[(formula['is_active']==True) & ~(formula['smb_positive'].isnull())][['name','smb_positive','pillar']]\n",
    "\n",
    "    df_unprocessed = df_unprocessed.loc[df_unprocessed.index.isin(active_factor,level='field')]\n",
    "    df_unprocessed = df_unprocessed.reset_index()\n",
    "    df_unprocessed = df_unprocessed.merge(formula_merge, how='left', left_on=['field'], right_on=['name'])\n",
    "\n",
    "    df_processed = df_unprocessed.set_index(['testing_period','field','group', 'pillar'])\n",
    "\n",
    "    return df_processed\n",
    "\n",
    "#=======================================================================================================================================================\n",
    "\n",
    "\n",
    "# def data_processing_value_for_each_field_and_trading_data_and_reverse(df_processed: pd.DataFrame = None):\n",
    "def categorizing_larger_between_smaller(df_reversed: pd.DataFrame = None):\n",
    "    df_reversed = df_reversed.reset_index().set_index(['field','testing_period','group', 'pillar'])\n",
    "    df_reversed = df_reversed.groupby(['testing_period','group', 'field', 'pillar'])['value'].transform(lambda x : '>0.001' if x.sum() >0.001 else '<-0.001' if x.sum() <-0.001 else '[-0.001,0.001]').rename('value')\n",
    "    return df_reversed\n",
    "\n",
    "def reversing_heuristics(df_processed: pd.DataFrame = None):\n",
    "    df_processed['sign'] = np.where(df_processed['smb_positive']==False,-1, 1)\n",
    "    df_processed['value'] = df_processed['value']*df_processed['sign']\n",
    "    df_reversed = df_processed.drop(columns=['sign','smb_positive'])\n",
    "    return df_reversed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market comparison functions\n",
    "def market_comparison_data_processing(df_all: pd.DataFrame = None):\n",
    "    df_processed = merge_factor_ratio_with_smb_and_retain_active_factor(df_all)\n",
    "    df_reversed = reversing_heuristics(df_processed=df_processed)\n",
    "    df_reversed_and_categorized = categorizing_larger_between_smaller(df_reversed)\n",
    "    return df_reversed_and_categorized\n",
    "\n",
    "\n",
    "def for_each_pillar_compare_different_markets(df_grouped: pd.DataFrame = None):\n",
    "    pillars = sorted(list(df_grouped.index.levels[3]))\n",
    "    markets = sorted(list(df_grouped.index.levels[2]))\n",
    "\n",
    "\n",
    "    for pillar in pillars:\n",
    "        year_ranges = [datetime.date(2008,1,1),datetime.date(2019,1,1),datetime.datetime.today().date()]\n",
    "\n",
    "        for year_range in year_ranges:\n",
    "            df_group = df_grouped.reset_index()\n",
    "            if year_range == datetime.date(2008,1,1):\n",
    "                df_group =  df_group.loc[df_group['testing_period']<year_range].set_index(['field','testing_period', 'group','pillar'])\n",
    "            elif year_range == datetime.date(2019,1,1):\n",
    "                df_group =  df_group.loc[(df_group['testing_period']>datetime.date(2008,1,1))&(df_group['testing_period']<year_range)].set_index(['field','testing_period', 'group','pillar'])\n",
    "            else:\n",
    "                df_group =  df_group.loc[(df_group['testing_period']>datetime.date(2019,1,1))&(df_group['testing_period']<year_range)].set_index(['field','testing_period', 'group','pillar'])\n",
    "\n",
    "            df_percent = df_group.groupby(['field','group', 'pillar']).value_counts(normalize=True).rename('value') # normalize to give percentage\n",
    "            fields_in_pillar = sorted(list(df_percent.loc[df_percent.index.isin([pillar],level='pillar')].index.get_level_values('field').drop_duplicates()))\n",
    "    \n",
    "            i=1\n",
    "            j=1\n",
    "            fig = make_subplots(rows=3, cols=10, subplot_titles=fields_in_pillar)\n",
    "            show_legend=True\n",
    "            df = df_percent\n",
    "            for field in fields_in_pillar:\n",
    "                if i==1 and j==1:\n",
    "                    show_legend=True\n",
    "                else:\n",
    "                    show_legend=False\n",
    "\n",
    "                \n",
    "                \n",
    "                bigger_than_pos_001 = df.loc[df.index.isin(['>0.001'],level='value')&(df.index.isin([pillar],level='pillar'))&(df.index.isin([field],level='field'))]*100\n",
    "\n",
    "\n",
    "                between = df.loc[df.index.isin(['[-0.001,0.001]'],level='value')&(df.index.isin([pillar],level='pillar'))&(df.index.isin([field],level='field'))]*100\n",
    "\n",
    "                between_hkd = between.loc[between.index.isin(['HKD'],level='group')]\n",
    "                between_cny = between.loc[between.index.isin(['CNY'],level='group')]\n",
    "                between_usd = between.loc[between.index.isin(['USD'],level='group')]\n",
    "                between_eur = between.loc[between.index.isin(['EUR'],level='group')]\n",
    "\n",
    "                between.loc[(field, 'HKD', pillar, '[-0.001,0.001]')] = 0 if len(between_hkd)==0 else between_hkd[0]\n",
    "                between.loc[(field, 'CNY', pillar, '[-0.001,0.001]')]  = 0 if len(between_cny)==0 else between_cny[0]\n",
    "                between.loc[(field, 'USD', pillar, '[-0.001,0.001]')]  = 0 if len(between_usd)==0 else between_usd[0]\n",
    "                between.loc[(field, 'EUR', pillar, '[-0.001,0.001]')]  = 0 if len(between_eur)==0 else between_eur[0]\n",
    "\n",
    "                between = between.sort_index(level='group')\n",
    "\n",
    "                less_than_neg_001 = df.loc[df.index.isin(['<-0.001'],level='value')&(df.index.isin([pillar],level='pillar'))&(df.index.isin([field],level='field'))]*100\n",
    "\n",
    "                fig.add_trace(go.Bar(x=['CNY', 'EUR', 'HKD', 'USD'], y=less_than_neg_001.tolist(), name='<-0.001', showlegend=show_legend, legendgroup='<-0.001',marker_color='red'), row=i, col =j)\n",
    "                fig.add_trace(go.Bar(x=['CNY', 'EUR', 'HKD', 'USD'], y=between.tolist(), name='[-0.001,0.001]', showlegend=show_legend, legendgroup='[-0.001,0.001]',marker_color='blue'), row=i, col =j)\n",
    "                fig.add_trace(go.Bar(x=['CNY', 'EUR', 'HKD', 'USD'], y=bigger_than_pos_001.tolist(), name='>0.001', showlegend=show_legend, legendgroup='>0.001',marker_color='yellow'), row=i, col =j)\n",
    "                fig.update_layout(barmode='stack')\n",
    "\n",
    "                if j>=9:\n",
    "                    j=1\n",
    "                    i = i+1\n",
    "                else:    \n",
    "                    j = j+1\n",
    "        \n",
    "            if year_range == datetime.date(2008,1,1):\n",
    "                text = 'before 2008'\n",
    "            elif year_range ==datetime.date(2019,1,1):\n",
    "                text = 'between 2008 and 2019'\n",
    "            else:\n",
    "                text = 'after 2019'\n",
    "            fig.update_layout(height=2000, width=2100, title_text=f\"Factor premium for different markets for pillar {pillar.upper()} \"+text)\n",
    "            # fig.show()\n",
    "            fig.write_html(f\"./market_comparison/market_comparison_{pillar}_{year_range}.html\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Periods comparison functions\n",
    "def period_comparison_data_processing(df_all: pd.DataFrame = None):\n",
    "    df_processed = merge_factor_ratio_with_smb_and_retain_active_factor(df_all)\n",
    "    df_reversed = reversing_heuristics(df_processed=df_processed)\n",
    "    df_reversed_and_categorized = categorizing_larger_between_smaller(df_reversed)\n",
    "    return df_reversed_and_categorized\n",
    "\n",
    "\n",
    "def for_each_pillar_compare_different_periods(df_grouped: pd.DataFrame = None):\n",
    "    pillars = sorted(list(df_grouped.index.levels[3]))\n",
    "    markets = sorted(list(df_grouped.index.levels[2]))\n",
    "\n",
    "\n",
    "    for pillar in pillars:\n",
    "        df_group = df_grouped.loc[df_grouped.index.isin([pillar],level='pillar')]\n",
    "        for market in markets:\n",
    "            df_group_market = df_group.loc[df_group.index.isin([market],level='group')]\n",
    "            fields_in_pillar = sorted(df_group_market.reset_index()['field'].drop_duplicates().tolist())\n",
    "            i=1\n",
    "            j=1\n",
    "            fig = make_subplots(rows=3, cols=10, subplot_titles=fields_in_pillar)\n",
    "            show_legend=True\n",
    "            for field in fields_in_pillar:\n",
    "                if i==1 and j==1:\n",
    "                    show_legend=True\n",
    "                else:\n",
    "                    show_legend=False\n",
    "        \n",
    "                df_group_field = df_group_market.loc[df_group_market.index.isin([field],level='field')]\n",
    "                df_group_year = df_group_field.reset_index()\n",
    "\n",
    "                df_group_before_2008_for_each_field =  df_group_year.loc[df_group_year['testing_period']<datetime.date(2008,1,1)].set_index(['field','testing_period', 'group','pillar']) \n",
    "                df_group_between_for_each_field =  df_group_year.loc[(df_group_year['testing_period']>datetime.date(2008,1,1))&(df_group_year['testing_period']<datetime.date(2019,1,1))].set_index(['field','testing_period', 'group','pillar'])\n",
    "                df_group_after_for_each_field =  df_group_year.loc[(df_group_year['testing_period']>datetime.date(2019,1,1))&(df_group_year['testing_period']<datetime.datetime.today().date())].set_index(['field','testing_period', 'group','pillar'])\n",
    "\n",
    "\n",
    "                df_group_before_2008_total_percentage = df_group_before_2008_for_each_field.groupby(['field']).value_counts(normalize=True).rename('value')   # normalize to give percentage\n",
    "                df_group_between_total_percentage = df_group_between_for_each_field.groupby(['field']).value_counts(normalize=True).rename('value')   # normalize to give percentage\n",
    "                df_group_after_total_percentage = df_group_after_for_each_field.groupby(['field']).value_counts(normalize=True).rename('value')   # normalize to give percentage\n",
    "\n",
    "\n",
    "                val_bigger_than_pos_001_before_2008 = df_group_before_2008_total_percentage.loc[df_group_before_2008_total_percentage.index.isin(['>0.001'],level='value')]\n",
    "                val_bigger_than_pos_001_between_2008_2019 = df_group_between_total_percentage.loc[df_group_between_total_percentage.index.isin(['>0.001'],level='value')]\n",
    "                val_bigger_than_pos_001_after = df_group_after_total_percentage.loc[df_group_after_total_percentage.index.isin(['>0.001'],level='value')]\n",
    "\n",
    "                val_less_than_neg_001_before_2008 = df_group_before_2008_total_percentage.loc[df_group_before_2008_total_percentage.index.isin(['<-0.001'],level='value')]\n",
    "                val_less_than_neg_001_between_2008_2019 = df_group_between_total_percentage.loc[df_group_between_total_percentage.index.isin(['<-0.001'],level='value')]\n",
    "                val_less_than_neg_001_after = df_group_after_total_percentage.loc[df_group_after_total_percentage.index.isin(['<-0.001'],level='value')]\n",
    "\n",
    "                val_between_before_2008 = df_group_before_2008_total_percentage.loc[df_group_before_2008_total_percentage.index.isin(['[-0.001,0.001]'],level='value')]\n",
    "                val_between_between_2008_2019 = df_group_between_total_percentage.loc[df_group_between_total_percentage.index.isin(['[-0.001,0.001]'],level='value')]\n",
    "                val_between_after = df_group_after_total_percentage.loc[df_group_after_total_percentage.index.isin(['[-0.001,0.001]'],level='value')]\n",
    "\n",
    "                val_between_before_2008_len = len(val_between_before_2008)\n",
    "                val_between_between_2008_2019_len = len(val_between_between_2008_2019)\n",
    "                val_between_after_len = len(val_between_after)\n",
    "\n",
    "\n",
    "                bigger_than_pos_001 = [val_bigger_than_pos_001_before_2008[0],val_bigger_than_pos_001_between_2008_2019[0],val_bigger_than_pos_001_after[0]]\n",
    "                less_than_neg_001 = [val_less_than_neg_001_before_2008[0],val_less_than_neg_001_between_2008_2019[0],val_less_than_neg_001_after[0]]\n",
    "                \n",
    "\n",
    "                val_between_before_2008 = 0 if val_between_before_2008_len == 0 else val_between_before_2008[0]\n",
    "                val_between_between_2008_2019 = 0 if val_between_between_2008_2019_len == 0 else val_between_between_2008_2019[0]\n",
    "                val_between_after = 0 if val_between_after_len == 0 else val_between_after[0]\n",
    "\n",
    "                between = [val_between_before_2008, val_between_between_2008_2019, val_between_after]\n",
    "\n",
    "                fig.add_trace(go.Bar(x=['Before 2008', 'Between 2008 and 2019', 'After 2019'], y=less_than_neg_001, name='<-0.001', showlegend=show_legend, legendgroup='<-0.001',marker_color='red'), row=i, col =j)\n",
    "                fig.add_trace(go.Bar(x=['Before 2008', 'Between 2008 and 2019', 'After 2019'], y=between, name='[-0.001,0.001]', showlegend=show_legend, legendgroup='[-0.001,0.001]',marker_color='blue'), row=i, col =j)\n",
    "                fig.add_trace(go.Bar(x=['Before 2008', 'Between 2008 and 2019', 'After 2019'], y=bigger_than_pos_001, name='>0.001', showlegend=show_legend, legendgroup='>0.001',marker_color='yellow'), row=i, col =j)\n",
    "                fig.update_layout(barmode='stack')\n",
    "\n",
    "                if j>=10:\n",
    "                    j=1\n",
    "                    i = i+1\n",
    "                else:    \n",
    "                    j = j+1\n",
    "        \n",
    "            fig.update_layout(height=2000, width=2100, title_text=f\"Factor premium for different year periods for pillar {pillar.upper()} for market {market.upper()}\")\n",
    "            # fig.show()\n",
    "            fig.write_html(f\"./period_comparison/periods_comparison_{pillar}_{market}.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph plotting functions\n",
    "\n",
    "def plot_histogram(data: pd.DataFrame = None, bin: int = 20, title: str = None, x_title: str = None, mean: pd.DataFrame = None, median: pd.DataFrame =None):\n",
    "    fig = px.histogram(data, nbins=bin, title=title, x=x_title, histnorm='probability', color='group')\n",
    "    mean_hkd = mean.loc[mean.index.isin(['HKD'],level='group')].values[0][0]\n",
    "    mean_cny = mean.loc[mean.index.isin(['CNY'],level='group')].values[0][0]\n",
    "    mean_eur = mean.loc[mean.index.isin(['EUR'],level='group')].values[0][0]\n",
    "    mean_usd = mean.loc[mean.index.isin(['USD'],level='group')].values[0][0]\n",
    "    \n",
    "    median_hkd = median.loc[median.index.isin(['HKD'],level='group')].values[0][0]\n",
    "    median_cny = median.loc[median.index.isin(['CNY'],level='group')].values[0][0]\n",
    "    median_eur = median.loc[median.index.isin(['EUR'],level='group')].values[0][0]\n",
    "    median_usd = median.loc[median.index.isin(['USD'],level='group')].values[0][0]\n",
    "    \n",
    "    dmax = data['value'].max()\n",
    "    dmin = data['value'].min()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=[mean_hkd,mean_hkd], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='green', width=1, dash='dash'),\n",
    "                         name=f'HKD_mean_{mean_hkd}'))\n",
    "    fig.add_trace(go.Scatter(x=[mean_usd,mean_usd], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='green', width=1, dash='dash'),\n",
    "                         name=f'USD_mean_{mean_usd}'))\n",
    "    fig.add_trace(go.Scatter(x=[mean_cny,mean_cny], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='green', width=1, dash='dash'),\n",
    "                         name=f'CNY_mean_{mean_cny}'))\n",
    "    fig.add_trace(go.Scatter(x=[mean_eur,mean_eur], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='green', width=1, dash='dash'),\n",
    "                         name=f'EUR_mean_{mean_eur}'))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=[median_hkd,median_hkd], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='red', width=1, dash='dash'),\n",
    "                         name=f'HKD_median_{median_hkd}'))\n",
    "    fig.add_trace(go.Scatter(x=[median_usd,median_usd], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='red', width=1, dash='dash'),\n",
    "                         name=f'USD_median_{median_usd}'))\n",
    "    fig.add_trace(go.Scatter(x=[median_cny,median_cny], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='red', width=1, dash='dash'),\n",
    "                         name=f'CNY_median_{median_cny}'))\n",
    "    fig.add_trace(go.Scatter(x=[median_eur,median_eur], \n",
    "                         y=[dmin,dmax], \n",
    "                         mode='lines', \n",
    "                         line=dict(color='red', width=1, dash='dash'),\n",
    "                         name=f'EUR_median_{median_eur}'))\n",
    "   \n",
    "    fig.write_html(f'./normal_distribution/{title}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading table all with market = USD\n",
      "Reading table all with market = HKD\n",
      "Reading table all with market = CNY\n",
      "Reading table all with market = EUR\n"
     ]
    }
   ],
   "source": [
    "#data preparation\n",
    "df_usd = read_table_all_from_factor_processed_ratio_20_pct_with_specified_market('USD')\n",
    "df_hkd = read_table_all_from_factor_processed_ratio_20_pct_with_specified_market('HKD')\n",
    "df_cny = read_table_all_from_factor_processed_ratio_20_pct_with_specified_market('CNY')\n",
    "df_eur = read_table_all_from_factor_processed_ratio_20_pct_with_specified_market('EUR')\n",
    "df_all = pd.concat([df_usd, df_hkd, df_cny, df_eur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading table\n"
     ]
    }
   ],
   "source": [
    "# Period comparison\n",
    "df_reversed_and_categorized_period = period_comparison_data_processing(df_all)\n",
    "for_each_pillar_compare_different_periods(df_reversed_and_categorized_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading table\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Market comparison\n",
    "df_reversed_and_categorized_market = market_comparison_data_processing(df_all)\n",
    "for_each_pillar_compare_different_markets(df_reversed_and_categorized_market)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram distribution\n",
    "def plot_histogram_for_different_markets_between(field:str = None, start_date: datetime.date = datetime.date(2000,1,1), end_date: datetime.date = datetime.date(2023,1,1)):\n",
    "    df_processed = merge_factor_ratio_with_smb_and_retain_active_factor(df_all)\n",
    "    df_reversed = reversing_heuristics(df_processed)\n",
    "    df = df_reversed.reset_index()\n",
    "    df = df.loc[(df['field']==field)&(df['testing_period']>start_date)&(df['testing_period']<end_date)][['value','group']]\n",
    "    \n",
    "    mean = df.set_index('group').groupby('group').mean()\n",
    "    median = df.set_index('group').groupby('group').median()\n",
    "\n",
    "    plot_histogram(df, title=f'Histogram_for_{field}_between_{start_date}_and_{end_date}', bin=400, x_title='value',mean=mean, median=median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading table\n"
     ]
    }
   ],
   "source": [
    "plot_histogram_for_different_markets_between('ebitda_to_ev', start_date=datetime.date(2019,1,1), end_date=datetime.date(2023,1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('factor-clustering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64bb343170ff9069bb97eb08fbc2a6e6a651d7677440b573165e544639dd1d87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
