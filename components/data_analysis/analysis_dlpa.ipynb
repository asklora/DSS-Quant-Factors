{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import os \n",
    "from typing import List\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import Engine\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import datetime\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import openpyxl\n",
    "from openpyxl.styles import Color\n",
    "from openpyxl.formatting.rule import ColorScale, FormatObject\n",
    "from openpyxl.formatting.rule import Rule\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "url = f\"postgresql://quant_ingestion:quant_ingestion@192.168.1.156:5432/quant_staging\"\n",
    "kwargs = dict(pool_size=1, max_overflow=-1, isolation_level=\"AUTOCOMMIT\", pool_pre_ping=True, pool_recycle=600,\n",
    "                      echo=False)\n",
    "\n",
    "def creating_engine():\n",
    "    \"\"\"This function creates a sqlalchemy engine using kwargs and url defined in this cell for query.\n",
    "\n",
    "    Returns:\n",
    "        engine (sqlalchemy.engine.Engine): sqlalchmey engine for connection\n",
    "    \"\"\"\n",
    "    print(f\"Creating sqlalchemy engine\")\n",
    "    engine = create_engine(url,**kwargs)\n",
    "    return engine\n",
    "\n",
    "engine = creating_engine()\n",
    "\n",
    "def read_dlpa_rating_ratios():\n",
    "    \"\"\"This function trading_day, field, value and ticker columns from dlpa_rating table.  \n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): Dataframe with 'trading_day','field','ticker' as index\n",
    "    \"\"\"\n",
    "    query = f\"\"\"SELECT trading_day, field, value , ticker FROM dlpa.dlpa_rating WHERE trading_day > '2022-01-01' AND field ='wts_rating';\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql(query,connection, index_col = ['trading_day','field','ticker'])\n",
    "    return df\n",
    "\n",
    "def read_data_tri():\n",
    "    \"\"\"This function reads trading_day, total_return_index and ticker columns from data_tri table.  \n",
    "\n",
    "    # Returns:\n",
    "    #     df (pd.DataFrame): Dataframe with 'trading_day','field','ticker' as index\n",
    "    \"\"\"\n",
    "    query = f\"\"\"SELECT trading_day, total_return_index, ticker FROM data.data_tri WHERE trading_day > '2022-01-01';\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        df_tri = pd.read_sql(query,connection)\n",
    "    return df_tri\n",
    "\n",
    "def get_stock_list_for_each_score(df):\n",
    "    score_list = df['value'].unique()\n",
    "    stock_map = {score:df.loc[df['value']==score].index.get_level_values('ticker').unique().tolist()for score in score_list}\n",
    "    return stock_map\n",
    "\n",
    "def populate_with_future_weekly_tri(df_dlpa: pd.DataFrame = None):\n",
    "    df_tri = read_data_tri()\n",
    "    df_dlpa = df_dlpa.reset_index()\n",
    "    df_dlpa['future_7_day'] = df_dlpa['trading_day'] + BDay(7)\n",
    "    df_tri['trading_day'] = pd.to_datetime(df_tri['trading_day'])\n",
    "    df_dlpa['trading_day'] = pd.to_datetime(df_dlpa['trading_day'])\n",
    "\n",
    "    df_dlpa = df_dlpa.rename(columns={\"value\":\"dlpa_prediction\"}).drop(columns=['field'])\n",
    "\n",
    "    df_tri_present =df_tri.rename(columns={'total_return_index':'present_tri'})\n",
    "    df_tri_future = df_tri.rename(columns={\"trading_day\":\"future_7_day\",'total_return_index':'future_7_day_tri'})\n",
    "\n",
    "\n",
    "\n",
    "    merged_present_tri = df_dlpa.merge(df_tri_present, how='left',on=['trading_day','ticker'])\n",
    "\n",
    "    merged_future_tri_and_present_tri = merged_present_tri.merge(df_tri_future,how='left',on=['future_7_day','ticker'])\n",
    "\n",
    "    merged_future_tri_and_present_tri = merged_future_tri_and_present_tri.dropna(how='any')\n",
    "\n",
    "    merged_future_tri_and_present_tri['percentage_change_of_tri'] = (merged_future_tri_and_present_tri['future_7_day_tri'] - merged_future_tri_and_present_tri['present_tri'])*100/merged_future_tri_and_present_tri['present_tri']\n",
    "    return merged_future_tri_and_present_tri\n",
    "\n",
    "def weekly_summary(df_wht_future_close: pd.DataFrame = None):\n",
    "    trading_day_list = df_wht_future_close['trading_day'].unique()\n",
    "    data = []\n",
    "    for trading_day in trading_day_list:\n",
    "        df = df_wht_future_close.loc[df_wht_future_close['trading_day']==trading_day]\n",
    "        mean = df.groupby(['dlpa_prediction'])[['trading_day','percentage_change_of_tri']].mean()\n",
    "        mean['trading_day'] = trading_day\n",
    "        data.append(mean)\n",
    "    weekly_sumary = pd.concat(data).reset_index().set_index(['dlpa_prediction','trading_day']).sort_index(level='dlpa_prediction')\n",
    "    # weekly_sumary.to_excel('weekly_summary.xlsx')\n",
    "    return weekly_sumary\n",
    "\n",
    "def producing_overall_summary(weekly_summary):\n",
    "    overall_summary = weekly_summary.groupby('dlpa_prediction').mean()\n",
    "    overall_summary = overall_summary.rename(columns={'percentage_change_of_tri':'mean'})\n",
    "\n",
    "    overall_summary['mean'] = overall_summary['mean'].apply(lambda x: np.format_float_positional(x,3,False,False,'k'))\n",
    "    weekly_summary['percentage_change_of_tri'] = weekly_summary['percentage_change_of_tri'].apply(lambda x: np.format_float_positional(x,3,False,False,'k'))\n",
    "\n",
    "\n",
    "    overall_summary = pd.merge(weekly_summary.reset_index().set_index('dlpa_prediction'), overall_summary , left_index=True, right_index=True).reset_index().set_index(['dlpa_prediction','mean'])\n",
    "    with pd.ExcelWriter('overall_summary.xlsx', engine='openpyxl') as writer:\n",
    "        overall_summary.to_excel(writer, merge_cells=True)\n",
    "    \n",
    "    return overall_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dlpa = read_dlpa_rating_ratios()\n",
    "df_with_future_close = populate_with_future_weekly_tri(df_dlpa)\n",
    "weekly_sumary = weekly_summary(df_with_future_close)\n",
    "overall_summaries = producing_overall_summary(weekly_sumary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('factor-clustering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64bb343170ff9069bb97eb08fbc2a6e6a651d7677440b573165e544639dd1d87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
